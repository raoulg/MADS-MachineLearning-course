{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable AI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making models is really cool, but in practice, in businesses people often also want to know why a certain prediction was made. Understanding why predictions are made is the field of Explainable AI. It can be as important, and in some cases, even more important as making the most accurate prediction. \n",
    "\n",
    "SHAP (SHapley Additive exPlainations) is a game theoretic approach to explain the output of any machine learning model to increase transparency and interpretability of machine learning models. Consider a coooperative game with the same number of players as the name of features. SHAP will disclose the individual contribution of each player (or feature) on the output of the model, for each example or observation.\n",
    "\n",
    "*Important: while SHAP shows the contribution or the importance of each feature on the prediction of the model, it does not evaluate the quality of the prediction itself.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP can thus be applied to all kinds of models. SHAP has different ways of working for different kinds of models, in this notebook we will first go through SHAP for tabular data. We will first make an XG Boost model, which is a tree model. We will use the breast_cancer dataset that has 30 variables and 1 target which is binary and shows whether the person has breast cancer or not. SHAP will help us understand which of these 30 variables made the largest difference in a single prediction. If we calculate the mean SHAP values over all these samples, we can say which of the variables are most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets as sk_datasets\n",
    "from typing import Any, TypedDict\n",
    "Tensor = torch.Tensor\n",
    "\n",
    "class Data(TypedDict):\n",
    "    train: TensorDataset\n",
    "    test: TensorDataset\n",
    "    features: list[str]\n",
    "\n",
    "class TensorDataset:\n",
    "    \"\"\"The main responsibility of the Dataset class is to\n",
    "    offer a __len__ method and a __getitem__ method\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data: Tensor, targets: Tensor) -> None:\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        assert len(data) == len(targets)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple:\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "def get_breast_cancer_dataset(\n",
    "    train_perc: float,\n",
    ") -> Data:\n",
    "    npdata = sk_datasets.load_breast_cancer()\n",
    "    featurenames = npdata.feature_names\n",
    "    tensordata = torch.tensor(npdata.data, dtype=torch.float32)\n",
    "    tensortarget = torch.tensor(npdata.target, dtype=torch.uint8)\n",
    "    trainidx = int(len(tensordata) * train_perc)\n",
    "    traindataset = TensorDataset(tensordata[:trainidx], tensortarget[:trainidx])\n",
    "    testdataset = TensorDataset(tensordata[trainidx:], tensortarget[trainidx:])\n",
    "    return {\"train\" : traindataset, \"test\": testdataset, \"features\" : list(featurenames)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_perc = 0.8\n",
    "data = get_breast_cancer_dataset(train_perc)\n",
    "traindataset = data[\"train\"]\n",
    "testdataset = data[\"test\"]\n",
    "featurenames = data[\"features\"]\n",
    "\n",
    "len(traindataset), len(testdataset), len(featurenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_datasets.base import BaseDatastreamer\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "\n",
    "preprocessor = BasePreprocessor()\n",
    "\n",
    "trainstreamer = BaseDatastreamer(traindataset, batchsize=32, preprocessor=preprocessor).stream()\n",
    "teststreamer = BaseDatastreamer(testdataset, batchsize=len(testdataset), preprocessor=preprocessor).stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = next(trainstreamer)\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, config: dict) -> None:\n",
    "        super().__init__()\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(config[\"input\"], config[\"h1\"]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(config[\"h1\"], config[\"h2\"]),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(config[\"h2\"], config[\"output\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        logits = self.linear(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "from mltrainer import Trainer, metrics, TrainerSettings, ReportTypes\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"input\" : 30,\n",
    "    \"h1\" : 20,\n",
    "    \"h2\" : 10,\n",
    "    \"output\" : 2\n",
    "}\n",
    "\n",
    "model = NeuralNetwork(config)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "accuracy = metrics.Accuracy()\n",
    "\n",
    "log_dir= Path(\"../../models/test\").resolve()\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=50,\n",
    "    metrics=[accuracy],\n",
    "    logdir=log_dir,\n",
    "    train_steps=int(train_perc * len(traindataset)) // 32,\n",
    "    valid_steps=1,\n",
    "    reporttypes=[ReportTypes.TENSORBOARD],\n",
    "    scheduler_kwargs={\"factor\": 0.5, \"patience\": 5},\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optim.Adam,\n",
    "    traindataloader=trainstreamer,\n",
    "    validdataloader=teststreamer,\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    "    )\n",
    "\n",
    "trainer.loop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a model! Now we can start using the SHAP values to analyze the model\n",
    "\n",
    "Because we are using a Neural network, we are using the DeepExplainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import pandas as pd\n",
    "\n",
    "X, Y = next(teststreamer)\n",
    "explainer = shap.DeepExplainer(model, X)\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "#make a dataframe of the data so that we can add the feature names in our plots\n",
    "df = pd.DataFrame(X.numpy(), columns=featurenames)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a single prediction\n",
    "\n",
    "We can visualize a single prediction. \n",
    "\n",
    "For this we can use the force plot, which is a way to see the effect of each feature on the prediction, for a given observation. In this plot the positive SHAP values are displayed on the left side and the negative on the right side, as if competing against each other. The highlighted value is the prediction for that observation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The input data has shape {X.shape}\")\n",
    "print(f\"This means we have {X.shape[0]} samples and {X.shape[1]} features\")\n",
    "print(\"The labels are either 0 or 1, so we have two classes\")\n",
    "vals = [f\"{x:.2f}\" for x in explainer.expected_value]\n",
    "print(f\"We have {vals} as the expected values for either class\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>The output value is the prediction for that observation </li>\n",
    "    <li>The base value: the mean prediction, or mean(yhat)</li>\n",
    "    <li>Red/blue: Features that push the prediction higher (to the right) are shown in red, and those pushing the prediction lower are in blue.</li>\n",
    "    <li>The plot is centered on the x-axis at explainer.expected_value. All SHAP values are relative to the model's expected value like a linear model's effects are relative to the intercept.</li>\n",
    "<ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#init javascript in order to display the visuals\n",
    "shap.initjs()\n",
    "\n",
    "\n",
    "category = 1\n",
    "observation = 3\n",
    "\n",
    "print(Y[observation])\n",
    "shap_value = np.array(shap_values[category][observation, :])\n",
    "features = df.iloc[observation,:]\n",
    "shap.force_plot(explainer.expected_value[category], shap_value, features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar chart of mean importance\n",
    "\n",
    "This takes the average of the SHAP value magnitudes across the dataset and plots it as a simple bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[1], df, plot_type=\"bar\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP Summary Plot\n",
    "\n",
    "Rather than use a typical feature importance bar chart, we use a density scatter plot of SHAP values for each feature to identify how much impact each feature has on the model output for individuals in the validation dataset. Features are sorted by the sum of the SHAP value magnitudes across all samples. It is interesting to note that the relationship feature has more total model impact than the captial gain feature, but for those samples where capital gain matters it has more impact than age. In other words, capital gain effects a few predictions by a large amount, while age effects all predictions by a smaller amount.\n",
    "\n",
    "Note that when the scatter points donâ€™t fit on a line they pile up to show density, and the color of each point represents the feature value of that individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[1], df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's it for the tabular data. We can also use SHAP for images. See the next notebook for SHAP on image data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-HWw5In8R-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "d7a2a84109baef7a65d7544440e725c32db11ce0f81af637277710b295bf52f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
