{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercises \n",
    "\n",
    "## 0. Setup your own repo\n",
    "- Setting up a repo is often repetitive. That's why you can use what are called 'cookiecutters', providing you with a template structure with some basic folders and files already set up for you. You don't have to use one, and can do it by hand, but have a look and maybe you think it is helpful.\n",
    "    - You could use the `cookiecutter` command that is preinstalled on your VM to create a repo, see https://github.com/raoulg/datascience-cookiecutter for details. I made this one myself, because I ended up editing the cookiecutter I was using.\n",
    "    - Another project is this one https://github.com/drivendata/cookiecutter-data-science , also intended for data science projects\n",
    "    - more general cookiecutters are shipped with tools like [pdm](https://pdm-project.org/latest/) and [rye](https://rye-up.com/); starting a project with `pdm init` or `rye init` (see docs for details) will provide you with some minimal structure, and there is the option to provide your own template with pdm (see [pdm template](https://pdm-project.org/latest/usage/template/))\n",
    "- push your own repo to github. Use `MADS-ML-{yourname}` as a format, eg `MADS-ML-JoostB`.\n",
    "- Invite me (raoulg; https://github.com/raoulg) as a collaborator to your repo.\n",
    "- make the excercises 1-5 below in your repo, and push them to github.\n",
    "\n",
    "Tips:\n",
    "- Commit often (every 30 minutes or so) \n",
    "- really, commit often. commiting and pushing your work is the best way to make sure your work is saved properly.\n",
    "- Commit groups of files that are related to each other. If you have more files, commit them separately.\n",
    "- Write commit messages that are descriptive and informative. \"lesson 1\", \"changes\" or \"commit\" are bad commit messages; \"added excercise 2\" is better, \"[exercise 2] added __len__ to Dataset class\" is even better.\n",
    "- Use `pdm` or `rye` to add dependencies. `mads_datasets` and `mltrainer` should cover a lot of what you need; don't blindly copy-paste all dependencies but keep your `pyproject.toml` as clean as possible.\n",
    "\n",
    "At some point, you will get a grade for the excercises that is 0 (not good enough), 1 (good enough) or 2 (excellent).\n",
    "I will look for both form and correctness to determine your grade.\n",
    "The result be incorporated into your final grade for this course.\n",
    "\n",
    "## 1. 3D Tensor dataset\n",
    "- Create a random 3D tensor dataset with `torch`\n",
    "- Build your own `DataSet` class, such that you can get a 3D tensor and a label (which can be a random 0 or 1)\n",
    "See notebook 03_dataloader for details on how to create a custom dataset. See 01_tensors and the torch documentation how to create random tensors.\n",
    "\n",
    "## 2. Datastreamers\n",
    "Study the `BaseDatastreamer` in `03_dataloader` and use it with your own dataset, such that you get a datastreamer that will keep on giving you new batches of data when you call `next()` or loop over it.\n",
    "\n",
    "# 3. Tune the network\n",
    "For this exercise we won't build upon the previous exercises, but instead will use the Fashion dataset.\n",
    "Run the experiment below, explore the different parameters (see suggestions below) and study the result with tensorboard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "from mltrainer import imagemodels, Trainer, TrainerSettings, ReportTypes, metrics\n",
    "\n",
    "import torch.optim as optim\n",
    "import gin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gin.parse_config_file(\"model.gin\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using `gin-config` to easily keep track of our experiments, and to easily save the different things we did during our experiments.\n",
    "\n",
    "The `model.gin` file is a simple file that will try to load parameters for funcitons that are already imported. \n",
    "\n",
    "So, if you wouldnt have imported train_model, the ginfile would not be able to parse settings for train_model.trainloop and will give an error.\n",
    "\n",
    "We can print all the settings that are operational with `gin.operative_config_str()` once we have loaded the functions to memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocessor = BasePreprocessor()\n",
    "fashionfactory = DatasetFactoryProvider.create_factory(DatasetType.FASHION)\n",
    "streamers = fashionfactory.create_datastreamer(batchsize=64, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]\n",
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gin.config_str())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A big advantage is that we can save this config as a file; that way it is easy to track what you changed during your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can set up a single experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=10,\n",
    "    metrics=[accuracy],\n",
    "    logdir=\"modellogs\",\n",
    "    train_steps=100,\n",
    "    valid_steps=100,\n",
    "    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.GIN],\n",
    ")\n",
    "model = imagemodels.NeuralNetwork(\n",
    "    num_classes=10, units1=256, units2=256)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optim.Adam,\n",
    "    traindataloader=trainstreamer,\n",
    "    validdataloader=validstreamer,\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    ")\n",
    "trainer.loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you can use `gin`, it will read the model.gin file, and instead of needing to set \n",
    "```python\n",
    "model = imagemodels.NeuralNetwork(\n",
    "    num_classes=10, units1=256, units2=256)\n",
    "\n",
    "```\n",
    "You can `gin.parce_config_file('model.gin')` and then set the model with `model = NeuralNetwork()`, and the parameters will be loaded from the gin file.\n",
    "\n",
    "If you want to combine this with a manual grid search, you could automate that with a double forloop:\n",
    "```python\n",
    "units = [256, 128, 64]\n",
    "for unit1 in units:\n",
    "    for unit2 in units:\n",
    "        ...\n",
    "```\n",
    "\n",
    "This is a very simple way to test multiple settings. The output looks like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = [256, 128, 64]\n",
    "for unit1 in units:\n",
    "    for unit2 in units:\n",
    "        print(f\"Units: {unit1}, {unit2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, this might not be the best way to search for a model; some configurations will be better than others (can you predict up front what will be the best configuration?).\n",
    "\n",
    "So, feel free to improve upon the gridsearch by adding your own logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "gin.parse_config_file(\"model.gin\")\n",
    "\n",
    "units = [256, 128, 64]\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=5,\n",
    "    metrics=[accuracy],\n",
    "    logdir=\"modellogs\",\n",
    "    train_steps=len(train),\n",
    "    valid_steps=len(valid),\n",
    "    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.GIN],\n",
    ")\n",
    "\n",
    "for unit1 in units:\n",
    "    for unit2 in units:\n",
    "        gin.bind_parameter(\"NeuralNetwork.units1\", unit1)\n",
    "        gin.bind_parameter(\"NeuralNetwork.units2\", unit2)\n",
    "\n",
    "        model = imagemodels.NeuralNetwork()\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            settings=settings,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optim.Adam,\n",
    "            traindataloader=trainstreamer,\n",
    "            validdataloader=validstreamer,\n",
    "            scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    "        )\n",
    "        trainer.loop()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment, and study the result with tensorboard. \n",
    "\n",
    "Locally, it is easy to do that with VS code itself. On the server, you have to take these steps:\n",
    "\n",
    "- in the terminal, `cd` to the location of the repository\n",
    "- activate the python environment for the shell. Note how the correct environment is being activated.\n",
    "- run `tensorboard --logdir=modellogs` in the terminal\n",
    "- tensorboard will launch at `localhost:6006` and vscode will notify you that the port is forwarded\n",
    "- you can either press the `launch` button in VScode or open your local browser at `localhost:6006`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Experiment with things like:\n",
    "\n",
    "- changing the amount of units1 and units2 to values between 16 and 1024. Use factors of 2: 16, 32, 64, etc.\n",
    "- changing the batchsize to values between 4 and 128. Again, use factors of two.\n",
    "- all your experiments are saved in the `modellogs` directory, with a timestamp. Inside you find a saved_config.gin file, that \n",
    "contains all the settings for that experiment. The `events` file is what tensorboard will show.\n",
    "- plot the result in a heatmap: units vs batchsize.\n",
    "- changing the learningrate to values between 1e-2 and 1e-5 \n",
    "- changing the optimizer from SGD to one of the other available algoritms at [torch](https://pytorch.org/docs/stable/optim.html) (scroll down for the algorithms)\n",
    "\n",
    "A note on train_steps: this is a setting that determines how often you get an update. \n",
    "Because our complete dataset is 938 (60000 / 64) batches long, you will need 938 trainstep to cover the complete 60.000 images.\n",
    "\n",
    "This can actually be a bit confusion, because every value below 938 changes the meaning of `epoch` slightly, because one epoch is no longer\n",
    "the full dataset, but simply `trainstep` batches. Setting trainsteps to 100 means you need to wait twice as long before you get feedback on the performance,\n",
    "as compared to trainsteps=50. You will also see that settings trainsteps to 100 improves the learning, but that is simply because the model has seen twice as \n",
    "much examples as compared to trainsteps=50.\n",
    "\n",
    "This implies that it is not usefull to compare trainsteps=50 and trainsteps=100, because setting it to 100 will always be better.\n",
    "Just pick an amount, and adjust your number of epochs accordingly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
