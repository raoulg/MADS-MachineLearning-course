{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Build a custom dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from typing import Iterator, Tuple, List\n",
    "# NB: you might get a cuda warning if you don't have a GPU available."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with images is that the size grows pretty fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (180, 180, 3)\n",
    "\n",
    "for i in [1, 10, 100]:\n",
    "    size = (i, ) + image_size\n",
    "    X = np.zeros(size)\n",
    "    size_byte = X.nbytes\n",
    "    print(f\"Size for {i} images: {size_byte / (2**20)} MB\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine what would happen if you actually have a million images! And no, the answer to this\n",
    "is not \"just get more RAM in the cloud\". You actually don't need to store everything at\n",
    "the same time in memory, right? So we will use the dataloader pattern to fix this problem. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow has a nice [collection of datasets](https://www.tensorflow.org/datasets) for machine learning tasks. Let's download the 'flower_photos' dataset. We will use that dataset for image classification later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "flowersfactory = DatasetFactoryProvider.create_factory(DatasetType.FLOWERS)\n",
    "flowersfactory.download_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = flowersfactory.subfolder\n",
    "print(image_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's  build a datagenerator from scratch; even though there are a lot of libraries (tensorflow, pytorch, trax) that provide datagenerators for images, it is a usefull practice to learn how the inside works. \n",
    "\n",
    "Eventually you will encounter a task were you will need to read in data from disk, and it is always usefull if you know how to adapt to a custom case. First step is to list all files in the directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_dir(path: Path) -> Iterator:\n",
    "    \"\"\"loops recursively through a folder\n",
    "\n",
    "    Args:\n",
    "        path (Path): folder to loop trough. If a directory\n",
    "            is encountered, loop through that recursively.\n",
    "\n",
    "    Yields:\n",
    "        Generator: all paths in a folder and subdirs.\n",
    "    \"\"\"\n",
    "\n",
    "    for p in Path(path).iterdir():\n",
    "        if p.is_dir():\n",
    "            yield from walk_dir(p)\n",
    "            continue\n",
    "        # resolve works like .absolute(), but it removes the \"../..\" parts\n",
    "        # of the location, so it is cleaner\n",
    "        yield p.resolve()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first file is a .txt file, so we will need to filter that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = walk_dir(image_folder)\n",
    "file1 = next(paths)\n",
    "file2 = next(paths)\n",
    "file1, file2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we now have a generator of paths in the directory. We can use a path to load an image from disk.\n",
    "The stucture that is often used for storing images is to have subfolders that indicate a label. \n",
    "This is an easy way to create a dataset by a human (just drag and drop the images in the right folder to label them).\n",
    "\n",
    "If the photo is inside the `tulips` subfolder, the class label should be `tulips`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "file = next(paths)\n",
    "img = Image.open(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `iter_valid_paths` function pulls all files, strips the corrects suffixes (we only want images), retrieves the classnames by gathering the names of the subfolders, and returns both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_datasets.settings import FileTypes\n",
    "for ft in FileTypes:\n",
    "    print(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_valid_paths(path: Path, formats: List[FileTypes]) -> Tuple[Iterator, List[str]]:\n",
    "    # gets all files in folder and subfolders\n",
    "    walk = walk_dir(path)\n",
    "    # retrieves foldernames as classnames\n",
    "    class_names = [subdir.name for subdir in path.iterdir() if subdir.is_dir()]\n",
    "    # keeps only specified formats\n",
    "    formats_ = [f.value for f in formats]\n",
    "    paths = (path for path in walk if path.suffix in formats_)\n",
    "    return paths, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formats = [FileTypes.JPG]\n",
    "paths, class_names = iter_valid_paths(\n",
    "    path = image_folder / \"flower_photos\",\n",
    "    formats=formats\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(paths), class_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, last, we need the `load_image` function.\n",
    "\n",
    "While there are multiple libraries available to load images (`pyvips`, `PIL`) the functions from `tensorflow` are the fastest for the sequence of tasks:\n",
    "- load image from disk\n",
    "- decode into an array of numbers\n",
    "- resize the image to a fixed size\n",
    "- cast to `numpy` array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgpath = next(paths)\n",
    "newsize = (150, 150)\n",
    "img_ = Image.open(imgpath).resize(newsize, Image.LANCZOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.asarray(img_)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(\n",
    "    path: Path, image_size: Tuple[int, int]\n",
    ") -> np.ndarray:\n",
    "    # load file\n",
    "    img_ = Image.open(path).resize(image_size, Image.LANCZOS)\n",
    "    return np.asarray(img_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit load_image(file, image_size=(180, 180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = next(paths)\n",
    "img = load_image(file, (180, 180))\n",
    "type(img), img.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to add a batchsize. This is a single image, so batchsize=1. We can do that by adding tuples like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1,) + img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.reshape(img, (1,) + img.shape)\n",
    "x.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at the image we loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(img.astype(np.uint8))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can construct our own data generator, using the design pattern we looked at in lesson 2.\n",
    "\n",
    "- We gather all the paths to files\n",
    "- We shuffle the index_list \n",
    "- For the range of `batchsize`, we use the `index_list[index]` design pattern to gather a random batch\n",
    "- label name is extacted from the subfolder name\n",
    "\n",
    "I implemented everything in the `src/data/data_tools.py` file, in a `Dataloader` class. Check out the file and study how I did that."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can time this, and it is fast enough, considering we have a batchsize of 32; I clocked 2.68ms for a single image, so that would give us about 86ms for just the loading of the 32 images from disk. Depending on things like my cpu temperature, I get around 98ms for a batch. The additional 22ms for resizing, decoding and casting to numpy for 32 images comes down to about 0.7ms per image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class BaseDataset:\n",
    "    \"\"\"The main responsibility of the Dataset class is to load the data from disk\n",
    "    and to offer a __len__ method and a __getitem__ method\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, paths: List[Path]) -> None:\n",
    "        self.paths = paths\n",
    "        random.shuffle(self.paths)\n",
    "        self.dataset: List = []\n",
    "        self.process_data()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple:\n",
    "        return self.dataset[idx]\n",
    "\n",
    "class ImgDataset(BaseDataset):\n",
    "    def __init__(self, paths, class_names, img_size):\n",
    "        self.img_size = img_size\n",
    "        self.class_names = class_names\n",
    "        super().__init__(paths)\n",
    "\n",
    "    def process_data(self) -> None:\n",
    "        for file in self.paths:\n",
    "            img = load_image(file, self.img_size)\n",
    "            x = np.reshape(img, (1,) + img.shape)\n",
    "            y = self.class_names.index(file.parent.name)\n",
    "            self.dataset.append((x, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths, class_names = iter_valid_paths(\n",
    "    path = image_folder / \"flower_photos\",\n",
    "    formats = [FileTypes.JPG],\n",
    ")\n",
    "dataset = ImgDataset([*paths], class_names, img_size=(150, 150))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these methods are wrapped together inside the datasetfactory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = flowersfactory.create_dataset()\n",
    "train = datasets[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train[1]\n",
    "x.shape, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the batch is now a pair of (img, label) tuples. However, we want to untangle a certain amount of them into a list of images and a list of labels.\n",
    "Think of this as unzipping a zipper. Weirdly enough, in python we use the same command for this as we would use to create the pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_processor(batch):\n",
    "    X, Y = zip(*batch)\n",
    "    return np.concatenate(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_datasets.base import BaseDatastreamer\n",
    "streamer = BaseDatastreamer(\n",
    "    dataset=train,\n",
    "    batchsize=32,\n",
    "    preprocessor=batch_processor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = streamer.stream()\n",
    "X, y = next(gen)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voila; we loaded 32 (img, label) pairs from the disk, and our streamer has selected 32 of those pairs and recombined them into a batch of 32 images, sized 150x150, with 3 channels (for colour). The labels are just an array of 32 labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit X, y = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamers = flowersfactory.create_datastreamer(batchsize=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-wM7qE7ca-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "45c41bdaf5373703b03bba2d9bd89c97dc8ee5add9f1112e039ff04603b8e2ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
