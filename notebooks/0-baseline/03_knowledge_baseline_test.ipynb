{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Python\n",
    "This notebook is intended to make a quick scan of different skills. It will test:\n",
    "\n",
    "- knowledge about mathematical notation (function definitions, sets) and a minimum of linear algebra (matrix multiplication)\n",
    "- numpy (generating data, concatenating, dotproduct)\n",
    "- generate a pandas dataframe, basic plotting\n",
    "- creating a class\n",
    "- basic efficiency (avoiding forloops with vectorization)\n",
    "- list comprehensions\n",
    "\n",
    "Before you do this test, make sure you went through the Vectorisation and\n",
    "Broadcasting notebook.\n",
    "\n",
    "# Don't worry if you get stuck\n",
    "this notebook is meant to identify the subjects\n",
    "where you will need more explanation!\n",
    "\n",
    "Some people might have a hard time with the mathematical notation. If so, **write\n",
    "down your questions and I will explain them**. Others might have no problem with\n",
    "that, but will have problems with classes, etc. Just use this as a test for\n",
    "finding the things I need to explain to you.\n",
    "\n",
    "Work on this, and please also keep track of your time (that gives me an\n",
    "indication of your working speed. This also differs widely over user groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 1\n",
    "### definition 1\n",
    ">Let there be $m$ observations $x_i \\in X$ with $i=\\{1, ..., m\\}$ where every observation has $n$ features: $x_i=\\{x_{i,1}, ..., x_{i,n}\\}$ \n",
    "\n",
    "We will represent these as a matrix $X$ with dimensions $(m, n)$ such that value $x_{i,j}$ is the $i^{th}$ observation for feature $j$.\n",
    "\n",
    "### objective\n",
    "\n",
    "Use numpy to create a matrix $X$ with $m=100, n=2$, filled with random floating point numbers. This will be our set of 100 observations with 2 features.\n",
    "\n",
    "<details>\n",
    "  <summary>HINT: Click to expand!</summary>\n",
    "\n",
    "  You can use `np.random.rand`\n",
    "  If you are not familiar, you can access the documentation directly from the jupyter notebook, by running either\n",
    "  `help(np.random.rand)` or `?np.random.rand`\n",
    "  \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 2\n",
    "\n",
    "### definition 2\n",
    ">We want to implement a function $f: \\mathbb{R}^m \\to \\mathbb{R}$ such that $$f(x) = wx + b$$\n",
    ">Here, $w$ are weights $w=\\{w_1, ..., w_n\\}$ where $n$ corresponds to the number of features and $b$ is an extra bias weight. We will initialize $w$ at random.\n",
    "\n",
    "\n",
    "**Example** if we observe a person $x_1$, as features let us measure someones height and shoe-size. Let us obtain $x_1=\\{1.84, 46\\}$.\n",
    "Now, let our randomly initialized weights $w$ be $\\{0.9, 0.2\\}$ and our $b=3$. With this, we would need to calculate: $0.9 * 1.84 + 0.2 * 46 + 3$ for that person.\n",
    "For a next person let us obtain $x_2=\\{1.65, 36\\}$, and thus we would need to calculate $0.9 * 1.65 + 0.2 * 36 + 3$.\n",
    "\n",
    "### definition 3\n",
    "To implement this more efficient, we will redefine the function slightly:\n",
    ">First, we add a dummy observation of 1 to the features: we get $x_i=\\{x_{i,1}, ..., x_{i,n}, 1\\}$\n",
    ">Then, we add the bias to the weights, such that we get $w=\\{w_1, ..., w_n, b\\}$.\n",
    ">With this, we can change the formula to $$f(x)= wx$$\n",
    "\n",
    "\n",
    "**Example** our previous example would be $x_1=\\{1.84, 46, 1\\}$ and $w=\\{0.9, 0.2, 3\\}$ and we would calculate $0.9 * 1.84 + 0.2 * 46 + 3 * 1$.\n",
    "\n",
    "### Objective\n",
    "To implement this , do the following:\n",
    "- create a columnvector $Xb$ where all entries are equal to 1, with dimensions $(m, 1)$. This will be the weight used for the bias. Do not hardcode $m$, but retrieve it from $X$.\n",
    "- concatenate the observations $X$ with $Xb$ along the columns, such that you get a matrix with dimensions $(m, n+1)$.\n",
    "- initialize a columnvector $w$ where you add the bias as one of the weights. So, it should have dimensions $(n+1, 1)$. Do not hardcode $n$, but retrieve it from $X$.\n",
    "- calculate $f(x)$ for all $m$\n",
    "- store the result of your calculation, that should have shape $(m, 1)$ in a variable `yhat`, which refers to your prediction $\\hat{y}$ \n",
    "\n",
    "<details>\n",
    "  <summary>HINT: Click to expand!</summary>\n",
    "  \n",
    "  For this, you can use the following numpy functions:\n",
    "  `np.ones`, `np.concatenate`, `np.random.rand` and `np.dot`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 3\n",
    "\n",
    "### Objective\n",
    "- concatenate $X$ and your prediction `yhat`\n",
    "- put them in a pandas dataframe, with column names 'height', 'shoe', 'bias' and 'yhat'.\n",
    "- make a scatterplot, with on the x-axis 'height', on the y-axis 'shoe', and use 'yhat' as a color.\n",
    "\n",
    "Make sure you have:\n",
    "- labels 'height' and 'shoe' on the x and y axis\n",
    "- a legend for the color\n",
    "- a title 'prediction'\n",
    "\n",
    "\n",
    "<details>\n",
    "  <summary>HINT: Click to expand!</summary>\n",
    "\n",
    "  For this excercise, you can use `np.concatenate`, `pd.DataFrame`, `sns.scatterplot` and `plt.title`.\n",
    "  Alternatively, you can completely use matplotlib `plt.scatter` or `plt.plot` for plotting, but getting the colors right will take much more coding then the sns.scatterplot oneliner.\n",
    "  \n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 4\n",
    "\n",
    "### Objective\n",
    "Create a class `LinearFunction` with three functions: `__init__`, `generate` and `predict`:\n",
    "\n",
    "*\\_\\_init__*\n",
    "- on initialization you pass variables $m$ and $n$, corresponding to $m$ observations with $n$ features.\n",
    "- store the original $(m,n)$ dimensions as a tuple in the object\n",
    "- you call the `generate` function\n",
    "\n",
    "*generate*\n",
    "- initialize random data using variables $n$ and $m$, add a column for the bias, \n",
    "- generate weights\n",
    "- store data and weights in the object\n",
    "\n",
    "*predict*\n",
    "- you return the result of $f(x)=wx+b$\n",
    "\n",
    "\n",
    "<details>\n",
    "  <summary>HINT: Click to expand!</summary>\n",
    "\n",
    "  This is mainly stitching together the previous lines of code into functions and a class.\n",
    "  So just reuse what you did before, and make sure everything works inside a function.\n",
    "  \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class LinearFunction:\n",
    "    def __init__(self, n, m):\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "    def predict(self):\n",
    "        return np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 5\n",
    "If you have implemented your formula efficiently, you should be able to scale it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "small = LinearFunction(1000, 3)\n",
    "yhat = small.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function should run in seconds. On my laptop (2.4 GHz Quad-Core Intel i5), I runs in 1.7 seconds.\n",
    "If it takes much longer, you didnt implement it efficiently and should go back to the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "big = LinearFunction(100000, 1000)\n",
    "yhat = big.predict()\n",
    "len(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code will test this solution for linear growing numbers (factor 10) of observations and features.\n",
    "The time it takes to compute should not grow with a factor 10, but slower.\n",
    "If the previous code did not run fast (eg around 2 seconds, but definitely below 10 sec) you should either fix that, or reduce the maximum numbers in the ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrange = range(2,5)\n",
    "mrange = range(1,4)\n",
    "heatmap_vec = np.zeros((len(nrange),len(mrange)))\n",
    "\n",
    "for i, n in enumerate([10**i for i in nrange]):\n",
    "    for j, m in enumerate([10**i for i in mrange]):\n",
    "        func = LinearFunction(n, m)\n",
    "        looptime = %timeit -o func.predict()\n",
    "        heatmap_vec[i, j] = looptime.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(heatmap_vec, annot=heatmap_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 6\n",
    "Define a variable `threshold=1`.\n",
    "Create a list comprehension that runs through the yhat, and assigns a value -1 for every value smaller then the threshold, else 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list comprehension that will select every item in X, if it is larger than\n",
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [1, 2, 3, 4, 5]\n",
    "select = None\n",
    "if select:\n",
    "    assert select == [3,4,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list comprehension that has the same result as this nested forloop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = [\"a\", \"b\", \"c\"]\n",
    "\n",
    "out = []\n",
    "for x in X:\n",
    "    for z in Z:\n",
    "        out.append(str(x) + z)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = None\n",
    "if out2:\n",
    "    assert out == out2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Make a list comprehension that both unpacks the values in the dictionary AND\n",
    "inverts the dictionary.\n",
    "\n",
    "hint: use a dict-comprehension, eg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"a\" : 1, \"b\" : 2}\n",
    "{v:k for k,v in d.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now recreate the nested forloop below with a dict-comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_data = {\"a\" : [1,2,3],\n",
    "               \"b\" : [10, 20, 30]}\n",
    "\n",
    "new_dict = {}\n",
    "for k,values in nested_data.items():\n",
    "    for v in values:\n",
    "        new_dict[v] = k\n",
    "new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict2 = None\n",
    "if new_dict2:\n",
    "    assert new_dict == new_dict2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
