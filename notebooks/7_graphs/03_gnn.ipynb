{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `pyproject.toml` file, under `[project.optional-dependencies]`, you can find the group `graphs`. To install this dependency, run:\n",
    "\n",
    "```bash\n",
    "pdm install -G graphs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric as tg\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx  # this is already a dependency of torch 2.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nodes = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "edges = torch.tensor([\n",
    "    [0, 1, 1, 2],\n",
    "    [1, 0, 2, 0]\n",
    "], dtype=torch.long)\n",
    "data = Data(x=nodes, edge_index=edges)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And cast them to networkx for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch_geometric.utils import to_networkx\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "g = to_networkx(data)\n",
    "nx.draw(g, with_labels=True, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that edge_index, i.e. the tensor defining the source and target nodes of all edges, is not a list of index tuples.\n",
    "- Note that it is necessary that the elements in edge_index only hold indices in the range `{ 0, ..., num_nodes - 1}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some basic properties of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Amount of nodes is {data.num_nodes}\")\n",
    "print(f\"Amount of edges is {data.num_edges}\")\n",
    "print(f\"Amount of node features is {data.num_node_features}\")\n",
    "print(f\"Amount of edge features is {data.num_edge_features}\")\n",
    "print(f\"The data is directed: {data.is_directed()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can cast networkx back to torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import from_networkx\n",
    "data = from_networkx(g)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cora dataset\n",
    "\n",
    "The cora dataset, visualized\n",
    "\n",
    "![](https://graphsandnetworks.com/wp-content/uploads/2019/09/CoraBalloons.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "cache = tg.get_home_dir()\n",
    "\n",
    "dataset = Planetoid(root=cache, name='Cora')\n",
    "\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]\n",
    "print('======================')\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2708 scientific publications \n",
    "- classified into one of seven classes. \n",
    "- The citation network consists of 5429 links. \n",
    "- Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words\n",
    "\n",
    "For the Cora dataset, the Data objects also holds a label for each node, and additional node-level attributes: train_mask, val_mask and test_mask, where\n",
    "- `train_mask` denotes against which nodes to train (140 nodes),\n",
    "- `val_mask` denotes which nodes to use for validation, e.g., to perform early stopping (500 nodes),\n",
    "- `test_mask` denotes against which nodes to test (1000 nodes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    0: \"Theory\",\n",
    "    1: \"Reinforcement_Learning\",\n",
    "    2: \"Genetic_Algorithms\",\n",
    "    3: \"Neural_Networks\",\n",
    "    4: \"Probabilistic_Methods\",\n",
    "    5: \"Case_Based\",\n",
    "    6: \"Rule_Learning\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "counter = collections.Counter(data.y.numpy())\n",
    "counter = dict(counter)\n",
    "print(counter)\n",
    "count = [x[1] for x in sorted(counter.items())]\n",
    "plt.bar(label_dict.values(), count)\n",
    "plt.xlabel(\"class\", size=20)\n",
    "plt.xticks(rotation=60);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a helperfunction to visualize the output of the GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "def visualize(h, color):\n",
    "    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\", alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the shape of our inputdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a 2D tensor, and hopefully you remember that we can use Linear layers for this.\n",
    "So lets create a simple network with 2 linear layers and a ReLU activation in between, and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, size_in: int, hidden: int, size_out: int):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(size_in, hidden)\n",
    "        self.linear2 = nn.Linear(hidden, size_out)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork(size_in=dataset.num_features, hidden=16, size_out=dataset.num_classes)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x)\n",
    "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch} | Loss {loss.item()}\")\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred = model(data.x).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is about 50 percent. Given that we would expect about 1/7th, or maybe 800 (majority class) / 2700 (total) = 30 percent, this is not too bad.\n",
    "If we visualize it, we can see that it's ordered, but not very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(data.x)\n",
    "visualize(out, color=data.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets use a basic convolutional layer instead of a linear layer.\n",
    "We are going to use the additional information from the structure of the data in this way, and we will learn about the neighborhood of each node.\n",
    "We are using 2 convolutions, so this will be a two-hop neighborhood accumulation of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden: int):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden)\n",
    "        self.conv2 = GCNConv(hidden, dataset.num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return x\n",
    "model = GCN(hidden=16)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train_mask.sum() , len(data.train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(hidden=16)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch} | Loss {loss.item()}\")\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That has improved a lot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(data)\n",
    "visualize(out, color=data.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, the visualisations shows how the data is much more organized, and the classes are much more separated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
