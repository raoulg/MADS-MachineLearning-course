# Les 6
De student begrijpt
6.1 - hoe de architectuur van een autoencoder in elkaar zit
6.2 - Wat een latent space is, en hoe je die kunt visualiseren
6.3 - Wat het contrast is tussen autoencoders en Supervised learning op punten als de latent space en de loss functie.
6.4 - Wat praktische toepassingen zijn van autoencoders en hoe de latent space gebruikt kan worden als half-fabrikaat voor andere modellen
6.5 - Hoe anomaly detection met een autoencoder werkt
6.6 - Hoe unsupervised classification met een autoencoder werkt
6.7 - Wat de elementen van een siamese network zijn
6.8 - Wanneer je siamese networks zou willen gebruiken
6.9 - Hoe je een dataloader moet aanpassen voor een autoencoder

De student kan
6.9 - Een autoencoder netwerk ontwerpen en hypertunen
6.10 - Een encoder of decoder uit een getrainde autoencoder hergebruiken

|                topic | description        |      page | code                                  |
|--------------------- | ------------       |  -------- | -----------------------               |
| 6.1 | what is the architecture of an AE   | 336-338   |  mltrainer.vae.py, 6_unsupervised/src |
| 6.2 | what is a latent space              | 338-339   | 6_unsupervised/src/show_vae.py        |
| 6.3 | contrast AE vs Supervised learning  | lesson    |                                       |
| 6.4 | practical applications of AE        | lesson    |                                       |
| 6.5 | anomaly detection with AE           | lesson    |                                       |
| 6.6 | unsupervised classification with AE | lesson    |                                       |
| 6.7 | elements of a siamese network       | lesson    |                                       |
| 6.8 | when to use siamese networks        | lesson    |                                       |
| 6.9 | how to adjust a dataloader for AE   | lesson    | 6_unsupervised/src/settings.py        |

https://youtu.be/qiUEgSCyY5o?si=AbXEZwyG6ISYaNi_